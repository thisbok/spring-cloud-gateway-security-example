package com.exec.services.analytics.consumer;

import com.exec.services.analytics.service.ApiGatewayLogService;
import com.exec.services.analytics.service.RealTimeAnalyticsService;
import com.exec.common.dto.ApiGatewayRequestLogDto;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

import java.time.LocalDateTime;
import java.util.List;

/**
 * ğŸ”„ API ë¡œê·¸ Kafka Consumer
 * <p>
 * Kafka ì—ì„œ API ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ì„ ì†Œë¹„í•˜ì—¬ Elasticsearch ì— ì €ì¥í•˜ê³ 
 * ì‹¤ì‹œê°„ ì§‘ê³„ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
 * <p>
 * ì¥ì :
 * 1. ë©”ì¸ API ì²˜ë¦¬ì™€ ë¡œê·¸ ì €ì¥ ì™„ì „ ë¶„ë¦¬
 * 2. ì¥ì•  ì‹œ ì¬ì²˜ë¦¬ ê°€ëŠ¥
 * 3. ë°°ì¹˜ ì²˜ë¦¬ë¡œ Elasticsearch ì„±ëŠ¥ ìµœì í™”
 * 4. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ ë¶„ì„ ê°€ëŠ¥
 * 5. DLQ íŒ¨í„´ìœ¼ë¡œ ì‹¤íŒ¨ ë©”ì‹œì§€ ì¶”ì  ë° ì¬ì²˜ë¦¬
 */
@Component
@RequiredArgsConstructor
@Slf4j
public class ApiLogKafkaConsumer {

    // DLQ Topic ì´ë¦„
    private static final String DLQ_TOPIC = "api-gateway-fail-logs";
    // ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    private static final int MAX_RETRY_COUNT = 3;
    private final ApiGatewayLogService apiGatewayLogService;
    private final RealTimeAnalyticsService realTimeAnalyticsService;
    private final KafkaTemplate<String, Object> kafkaTemplate;

    /**
     * API í˜¸ì¶œ ë¡œê·¸ ì¼ê´„ ì²˜ë¦¬ Consumer
     * <p>
     * íŠ¹ì§•:
     * - ë°°ì¹˜ ì²˜ë¦¬ë¡œ Elasticsearch ì„±ëŠ¥ ìµœì í™”
     * - ìˆ˜ë™ ì»¤ë°‹ìœ¼ë¡œ ì¥ì•  ì‹œ ì¬ì²˜ë¦¬ ë³´ì¥
     * - DLQ(Dead Letter Queue) ì§€ì›
     */
    @KafkaListener(
            topics = "api-gateway-request-logs",
            groupId = "api-log-elasticsearch-group",
            containerFactory = "batchKafkaListenerContainerFactory"
    )
    public void consumeApiCallLogsBatch(
            @Payload List<ApiGatewayRequestLogDto> logDtos,
            @Header(KafkaHeaders.RECEIVED_PARTITION) List<Integer> partitions,
            @Header(KafkaHeaders.OFFSET) List<Long> offsets,
            Acknowledgment acknowledgment) {

        try {
            log.info("ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {} ê±´ì˜ API ë¡œê·¸", logDtos.size());

            // 1. Elasticsearch ë°°ì¹˜ ì €ì¥
            bulkSaveToElasticsearch(logDtos);

            // 2. ì‹¤ì‹œê°„ ì§‘ê³„ ì—…ë°ì´íŠ¸
            updateRealTimeAggregates(logDtos);

            // 3. ìˆ˜ë™ ì»¤ë°‹ (ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ í›„)
            acknowledgment.acknowledge();

            log.info("ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {} ê±´", logDtos.size());

        } catch (Exception e) {
            log.error("ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {} ê±´", logDtos.size(), e);
            // DLQ ë¡œ ì „ì†¡í•˜ê±°ë‚˜ ì¬ì‹œë„ ë¡œì§ êµ¬í˜„
            handleBatchProcessingError(logDtos, e);
        }
    }

    /**
     * ì‹¤ì‹œê°„ ë¶„ì„ìš© Consumer (ë³„ë„ ê·¸ë£¹)
     * <p>
     * ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ:
     * 1. ì¼ì‹œì  ì˜¤ë¥˜ (ë„¤íŠ¸ì›Œí¬, DB): ì¬ì‹œë„ (offset ì»¤ë°‹ ì•ˆí•¨)
     * 2. ì˜êµ¬ì  ì˜¤ë¥˜ (ë°ì´í„° í˜•ì‹): DLQ ì „ì†¡ í›„ ì»¤ë°‹
     * 3. ë¶„ì„ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ë¡œê¹… í›„ ì»¤ë°‹
     */
    @KafkaListener(
            topics = "api-gateway-request-logs",
            groupId = "api-log-realtime-group",
            concurrency = "3"
    )
    public void consumeForRealTimeAnalysis(
            @Payload ApiGatewayRequestLogDto logDto,
            @Header(KafkaHeaders.RECEIVED_PARTITION) int partition,
            @Header(KafkaHeaders.OFFSET) long offset,
            Acknowledgment acknowledgment) {

        try {
            log.debug("ì‹¤ì‹œê°„ ë¶„ì„ ì²˜ë¦¬: {}", logDto.getRequestId());

            // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            realTimeAnalyticsService.processApiCallLog(logDto);

            // ì´ìƒ ì§•í›„ íƒì§€
            detectAnomalies(logDto);

            // ì•Œë¦¼ íŠ¸ë¦¬ê±° í™•ì¸
            checkAlertConditions(logDto);

            // ì„±ê³µ: offset ì»¤ë°‹
        } catch (Exception e) {
            // ì—ëŸ¬ ì²˜ë¦¬: ë¶„ì„ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ì»¤ë°‹
            // ì—ëŸ¬ ë¡œê¹… (ìƒì„¸ ì •ë³´ í¬í•¨)
            String errorType = classifyError(e);

            log.error("[ì‹¤ì‹œê°„ ë¶„ì„ ì‹¤íŒ¨] requestId={}, errorType={}, message={}",
                    logDto.getRequestId(),
                    errorType,
                    e.getMessage(),
                    e);
        }
        acknowledgment.acknowledge();
    }

    /**
     * ì—ëŸ¬ ë¡œê·¸ ì „ìš© Consumer
     */
    @KafkaListener(
            topics = "api-errors",
            groupId = "api-error-monitoring-group"
    )
    public void consumeErrorLogs(
            @Payload ApiGatewayRequestLogDto errorLogDto,
            Acknowledgment acknowledgment) {

        try {
            log.warn("ì—ëŸ¬ ë¡œê·¸ ì²˜ë¦¬: {} - {}",
                    errorLogDto.getRequestId(),
                    errorLogDto.getStatusCode());

            // ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
            analyzeErrorPattern(errorLogDto);

            // ê¸´ê¸‰ ì•Œë¦¼ ë°œì†¡
            sendUrgentAlert(errorLogDto);

            // Elasticsearch ì—ëŸ¬ ì¸ë±ìŠ¤ì— ì €ì¥
            saveToErrorIndex(errorLogDto);

            acknowledgment.acknowledge();

        } catch (Exception e) {
            log.error("ì—ëŸ¬ ë¡œê·¸ ì²˜ë¦¬ ì‹¤íŒ¨: {}", errorLogDto.getRequestId(), e);
        }
    }

    /**
     * Elasticsearch ë°°ì¹˜ ì €ì¥
     */
    private void bulkSaveToElasticsearch(List<ApiGatewayRequestLogDto> logDtos) {
        try {
            // Spring Data Elasticsearch ë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ ì €ì¥
            apiGatewayLogService.saveLogsBatch(logDtos);

            log.debug("Elasticsearch ë°°ì¹˜ ì €ì¥ ì™„ë£Œ: {} ê±´", logDtos.size());

        } catch (Exception e) {
            log.error("Elasticsearch ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨", e);
            throw new RuntimeException("Elasticsearch ì €ì¥ ì‹¤íŒ¨", e);
        }
    }

    /**
     * ì‹¤ì‹œê°„ ì§‘ê³„ ì—…ë°ì´íŠ¸
     */
    private void updateRealTimeAggregates(List<ApiGatewayRequestLogDto> logDtos) {
        try {
            for (ApiGatewayRequestLogDto logDto : logDtos) {
                // Redis ê¸°ë°˜ ì‹¤ì‹œê°„ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                realTimeAnalyticsService.incrementCounters(logDto);

                // ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                realTimeAnalyticsService.updateSlidingWindow(logDto);
            }

        } catch (Exception e) {
            log.error("ì‹¤ì‹œê°„ ì§‘ê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨", e);
            // ì§‘ê³„ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë˜ì§€ì§€ ì•ŠìŒ
        }
    }

    /**
     * ì´ìƒ ì§•í›„ íƒì§€
     */
    private void detectAnomalies(ApiGatewayRequestLogDto logDto) {
        try {
            // ì‘ë‹µ ì‹œê°„ ì´ìƒ
            if (logDto.getResponseTimeMs() != null && logDto.getResponseTimeMs() > 5000) {
                log.warn("ì‘ë‹µ ì‹œê°„ ì´ìƒ íƒì§€: {}ms - {}",
                        logDto.getResponseTimeMs(), logDto.getRequestId());
            }

            // accessKey ê¸°ë°˜ ëª¨ë‹ˆí„°ë§ (ì¸ì¦ ì‹¤íŒ¨ ì‹œì—ë„ ì¶”ì  ê°€ëŠ¥)
            String accessKey = logDto.getAccessKey();
            if (accessKey == null) {
                log.warn("AccessKey ëˆ„ë½ìœ¼ë¡œ ì´ìƒ ì§•í›„ íƒì§€ ê±´ë„ˆëœ€: {}", logDto.getRequestId());
                return;
            }

            // ì—ëŸ¬ìœ¨ ê¸‰ì¦
            if (logDto.getHasError()) {
                realTimeAnalyticsService.checkErrorRateSpike(accessKey);
            }

            // íŠ¸ë˜í”½ ê¸‰ì¦
            realTimeAnalyticsService.checkTrafficSpike(accessKey);

        } catch (Exception e) {
            log.error("ì´ìƒ ì§•í›„ íƒì§€ ì‹¤íŒ¨: {}", logDto.getRequestId(), e);
        }
    }

    /**
     * ì•Œë¦¼ ì¡°ê±´ í™•ì¸
     */
    private void checkAlertConditions(ApiGatewayRequestLogDto logDto) {
        // 5xx ì—ëŸ¬ ì•Œë¦¼
        if (logDto.getStatusCode() != null && logDto.getStatusCode() >= 500) {
            sendServerErrorAlert(logDto);
        }

        // API í‚¤ ì œí•œ ì´ˆê³¼
        if (logDto.getStatusCode() != null && logDto.getStatusCode() == 429) {
            sendRateLimitAlert(logDto);
        }

        // ë³´ì•ˆ ìœ„í—˜ íƒì§€
        if ("HIGH".equals(logDto.getSecurityRiskLevel())) {
            sendSecurityAlert(logDto);
        }
    }

    /**
     * ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
     */
    private void analyzeErrorPattern(ApiGatewayRequestLogDto errorLogDto) {
        // TODO: ì—ëŸ¬ íŒ¨í„´ ë¶„ì„ ë¡œì§ êµ¬í˜„
        log.info("ì—ëŸ¬ íŒ¨í„´ ë¶„ì„: {}", errorLogDto.getErrorMessage());
    }

    /**
     * ê¸´ê¸‰ ì•Œë¦¼ ë°œì†¡
     */
    private void sendUrgentAlert(ApiGatewayRequestLogDto errorLogDto) {
        // TODO: ê¸´ê¸‰ ì•Œë¦¼ ë°œì†¡ ë¡œì§ êµ¬í˜„
        log.warn("ê¸´ê¸‰ ì•Œë¦¼ ë°œì†¡: {}", errorLogDto.getRequestId());
    }

    /**
     * ì—ëŸ¬ ì¸ë±ìŠ¤ ì €ì¥
     */
    private void saveToErrorIndex(ApiGatewayRequestLogDto errorLogDto) {
        try {
            // ì¼ë°˜ ë¡œê·¸ ì¸ë±ìŠ¤ì— ì €ì¥ (ì—ëŸ¬ë„ ë™ì¼í•œ ì¸ë±ìŠ¤ ì‚¬ìš©)
            apiGatewayLogService.saveLog(errorLogDto);
        } catch (Exception e) {
            log.error("ì—ëŸ¬ ì¸ë±ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {}", errorLogDto.getRequestId(), e);
        }
    }

    /**
     * ì„œë²„ ì—ëŸ¬ ì•Œë¦¼
     */
    private void sendServerErrorAlert(ApiGatewayRequestLogDto logDto) {
        log.error("ì„œë²„ ì—ëŸ¬ ì•Œë¦¼: {} {} - Status: {}",
                logDto.getMethod(), logDto.getUri(), logDto.getStatusCode());
    }

    /**
     * Rate Limit ì•Œë¦¼
     */
    private void sendRateLimitAlert(ApiGatewayRequestLogDto logDto) {
        log.warn("Rate Limit ì´ˆê³¼ ì•Œë¦¼: AccessKey {} (Client: {}) - {}",
                logDto.getAccessKey(), logDto.getClientId(), logDto.getRequestId());
    }

    /**
     * ë³´ì•ˆ ì•Œë¦¼
     */
    private void sendSecurityAlert(ApiGatewayRequestLogDto logDto) {
        log.error("ë³´ì•ˆ ìœ„í—˜ íƒì§€: {} - {}",
                logDto.getRequestId(), logDto.getAttackType());
    }

    /**
     * ì—ëŸ¬ ìœ í˜• ë¶„ë¥˜
     */
    private String classifyError(Exception error) {
        if (error instanceof org.springframework.data.redis.RedisConnectionFailureException) {
            return "REDIS_CONNECTION_FAILURE";
        } else if (error instanceof java.net.ConnectException) {
            return "NETWORK_ERROR";
        } else if (error instanceof NullPointerException) {
            return "NULL_POINTER";
        } else if (error instanceof IllegalArgumentException) {
            return "INVALID_DATA";
        } else {
            return "UNKNOWN_ERROR";
        }
    }

    // ==================== DLQ ì „ì†¡ ====================

    /**
     * Dead Letter Queue ë¡œ ë©”ì‹œì§€ ì „ì†¡
     * <p>
     * ì‹¤íŒ¨í•œ ë©”ì‹œì§€ë¥¼ ë³„ë„ Kafka Topic ìœ¼ë¡œ ì „ì†¡í•˜ì—¬:
     * 1. ë©”ì‹œì§€ ìœ ì‹¤ ë°©ì§€
     * 2. ì¶”í›„ ì¬ì²˜ë¦¬ ê°€ëŠ¥
     * 3. ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
     * 4. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼
     */
    private void sendToDeadLetterQueue(
            ApiGatewayRequestLogDto originalMessage,
            Exception error,
            int retryCount) {

        try {
            // DLQ ë©”ì‹œì§€ ìƒì„± (ë©”íƒ€ë°ì´í„° í¬í•¨)
            FailedLogMessage failedMessage = FailedLogMessage.builder()
                    .originalMessage(originalMessage)
                    .errorType(classifyError(error))
                    .errorMessage(error.getMessage())
                    .stackTrace(getStackTrace(error))
                    .retryCount(retryCount)
                    .failedAt(LocalDateTime.now())
                    .requestId(originalMessage.getRequestId())
                    .clientId(originalMessage.getClientId())
                    .accessKey(originalMessage.getAccessKey())
                    .build();

            // DLQ Topic ìœ¼ë¡œ ì „ì†¡
            kafkaTemplate.send(DLQ_TOPIC, originalMessage.getRequestId(), failedMessage)
                    .whenComplete((result, ex) -> {
                        if (ex != null) {
                            log.error("DLQ ì „ì†¡ ì‹¤íŒ¨: requestId={}", originalMessage.getRequestId(), ex);
                            // DLQ ì „ì†¡ë„ ì‹¤íŒ¨í•œ ê²½ìš° ë¡œì»¬ íŒŒì¼ì— ì €ì¥ (ìµœí›„ì˜ ìˆ˜ë‹¨)
                            saveToLocalFile(failedMessage);
                        } else {
                            log.info("DLQ ì „ì†¡ ì„±ê³µ: requestId={}, retryCount={}",
                                    originalMessage.getRequestId(), retryCount);
                        }
                    });

        } catch (Exception e) {
            log.error("DLQ ì „ì†¡ ì¤‘ ì˜ˆì™¸ ë°œìƒ: requestId={}",
                    originalMessage.getRequestId(), e);
            saveToLocalFile(FailedLogMessage.builder()
                    .originalMessage(originalMessage)
                    .errorMessage(error.getMessage())
                    .build());
        }
    }

    /**
     * ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
     */
    private String getStackTrace(Exception error) {
        if (error == null) return null;

        java.io.StringWriter sw = new java.io.StringWriter();
        error.printStackTrace(new java.io.PrintWriter(sw));
        String stackTrace = sw.toString();

        // ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„ (Kafka ë©”ì‹œì§€ í¬ê¸° ì œí•œ ê³ ë ¤)
        return stackTrace.length() > 5000
                ? stackTrace.substring(0, 5000) + "\n... (truncated)"
                : stackTrace;
    }

    /**
     * DLQ ì „ì†¡ë„ ì‹¤íŒ¨í•œ ê²½ìš° ë¡œì»¬ íŒŒì¼ì— ì €ì¥ (ìµœí›„ì˜ ìˆ˜ë‹¨)
     */
    private void saveToLocalFile(FailedLogMessage failedMessage) {
        try {
            // TODO: ì‹¤ì œ íŒŒì¼ ì €ì¥ ë¡œì§ êµ¬í˜„
            log.warn("ë¡œì»¬ íŒŒì¼ ì €ì¥ í•„ìš”: requestId={}", failedMessage.getRequestId());
            // ì˜ˆ: /var/log/analytics/failed-messages/{date}/{requestId}.json
        } catch (Exception e) {
            log.error("ë¡œì»¬ íŒŒì¼ ì €ì¥ë„ ì‹¤íŒ¨", e);
        }
    }

    /**
     * ë°°ì¹˜ ì²˜ë¦¬ ì—ëŸ¬ í•¸ë“¤ë§
     * <p>
     * ë°°ì¹˜ ì²˜ë¦¬ëŠ” í•µì‹¬ ê¸°ëŠ¥ì´ë¯€ë¡œ ë” ì‹ ì¤‘í•œ ì²˜ë¦¬ í•„ìš”
     */
    private void handleBatchProcessingError(List<ApiGatewayRequestLogDto> logDtos, Exception error) {
        String errorType = classifyError(error);

        log.error("[ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨] count={}, errorType={}, message={}",
                logDtos.size(),
                errorType,
                error.getMessage(),
                error);

        // ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì „ëµ
        if (isRetryableError(error)) {
            // ì¼ì‹œì  ì˜¤ë¥˜: offset ì»¤ë°‹í•˜ì§€ ì•Šê³  ì¬ì‹œë„ ìœ ë„
            log.warn("ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ - offset ì»¤ë°‹ ìƒëµ: {}", errorType);
            // acknowledgment.acknowledge() ë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ â†’ ì¬ì‹œë„ë¨

        } else {
            // ì˜êµ¬ì  ì˜¤ë¥˜: ê°œë³„ ì²˜ë¦¬ ì‹œë„
            log.error("ì˜êµ¬ì  ì—ëŸ¬ - ê°œë³„ ì²˜ë¦¬ ì‹œë„: {}", errorType);
            processBatchIndividually(logDtos);

            // DLQ ì „ì†¡ (ì‹¤íŒ¨í•œ í•­ëª©ë§Œ)
            // sendToDeadLetterQueue(logDtos, error);
        }
    }

    /**
     * ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ ì—¬ë¶€ íŒë‹¨
     */
    private boolean isRetryableError(Exception error) {
        // ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, DB ì—°ê²° ì˜¤ë¥˜ ë“±ì€ ì¬ì‹œë„ ê°€ëŠ¥
        return error instanceof org.springframework.dao.TransientDataAccessException
                || error instanceof java.net.ConnectException
                || error instanceof org.springframework.data.redis.RedisConnectionFailureException;
    }

    /**
     * ë°°ì¹˜ë¥¼ ê°œë³„ í•­ëª©ìœ¼ë¡œ ì²˜ë¦¬
     */
    private void processBatchIndividually(List<ApiGatewayRequestLogDto> logDtos) {
        log.info("ë°°ì¹˜ ê°œë³„ ì²˜ë¦¬ ì‹œì‘: {} ê±´", logDtos.size());

        int successCount = 0;
        int failureCount = 0;

        for (ApiGatewayRequestLogDto logDto : logDtos) {
            try {
                apiGatewayLogService.saveLog(logDto);
                successCount++;
            } catch (Exception e) {
                log.error("ê°œë³„ í•­ëª© ì²˜ë¦¬ ì‹¤íŒ¨: requestId={}", logDto.getRequestId(), e);
                // ê°œë³„ ì‹¤íŒ¨ëŠ” DLQ ë¡œ ì „ì†¡
                sendToDeadLetterQueue(logDto, e, 1);
                failureCount++;
            }
        }

        log.info("ë°°ì¹˜ ê°œë³„ ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ={}, ì‹¤íŒ¨={}", successCount, failureCount);
    }

    // ==================== DLQ Consumer ====================

    /**
     * DLQ Consumer: ì‹¤íŒ¨í•œ ë©”ì‹œì§€ ì¬ì²˜ë¦¬
     * <p>
     * ì‹¤ë¬´ ìš´ì˜ ì‹œë‚˜ë¦¬ì˜¤:
     * 1. DLQ ë©”ì‹œì§€ ëª¨ë‹ˆí„°ë§ (ì•Œë¦¼ ë°œì†¡)
     * 2. ìˆ˜ë™ í™•ì¸ ë° ì¡°ì¹˜
     * 3. ì¬ì²˜ë¦¬ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
     * 4. ì¬ì²˜ë¦¬ ë˜ëŠ” ì˜êµ¬ ë³´ê´€
     */
    @KafkaListener(
            topics = DLQ_TOPIC,
            groupId = "api-gateway-fail-log-group",
            concurrency = "1"  // DLQ ëŠ” ë‹¨ì¼ ìŠ¤ë ˆë“œë¡œ ì²œì²œíˆ ì²˜ë¦¬
    )
    public void consumeFailedLogs(
            @Payload FailedLogMessage failedMessage,
            Acknowledgment acknowledgment) {

        try {
            log.warn("DLQ ë©”ì‹œì§€ ìˆ˜ì‹ : requestId={}, errorType={}, retryCount={}",
                    failedMessage.getRequestId(),
                    failedMessage.getErrorType(),
                    failedMessage.getRetryCount());

            // ì¬ì‹œë„ íšŸìˆ˜ ì²´í¬
            if (failedMessage.getRetryCount() >= MAX_RETRY_COUNT) {
                log.error("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: requestId={}, retryCount={}",
                        failedMessage.getRequestId(), failedMessage.getRetryCount());

                // ì˜êµ¬ ì‹¤íŒ¨ ì²˜ë¦¬ (DB ì— ì €ì¥, ì•Œë¦¼ ë°œì†¡ ë“±)
                handlePermanentFailure(failedMessage);

                // offset ì»¤ë°‹ (ë” ì´ìƒ ì¬ì‹œë„ ì•ˆí•¨)
                acknowledgment.acknowledge();
                return;
            }

            // ì¬ì²˜ë¦¬ ì‹œë„
            boolean retrySuccess = retryFailedMessage(failedMessage);

            if (retrySuccess) {
                log.info("DLQ ë©”ì‹œì§€ ì¬ì²˜ë¦¬ ì„±ê³µ: requestId={}", failedMessage.getRequestId());
                acknowledgment.acknowledge();
            } else {
                log.warn("DLQ ë©”ì‹œì§€ ì¬ì²˜ë¦¬ ì‹¤íŒ¨: requestId={}, ì¬ì‹œë„ ì¹´ìš´íŠ¸ ì¦ê°€",
                        failedMessage.getRequestId());

                // ì¬ì‹œë„ ì¹´ìš´íŠ¸ ì¦ê°€ í›„ ë‹¤ì‹œ DLQ ë¡œ ì „ì†¡
                sendToDeadLetterQueue(
                        failedMessage.getOriginalMessage(),
                        new RuntimeException(failedMessage.getErrorMessage()),
                        failedMessage.getRetryCount() + 1
                );

                // offset ì»¤ë°‹ (ë‹¤ìŒ ì¬ì‹œë„ëŠ” ìƒˆë¡œìš´ DLQ ë©”ì‹œì§€ë¡œ)
                acknowledgment.acknowledge();
            }

        } catch (Exception e) {
            log.error("DLQ Consumer ì²˜ë¦¬ ì‹¤íŒ¨: requestId={}",
                    failedMessage.getRequestId(), e);
            // ì¹˜ëª…ì  ì—ëŸ¬: offset ì»¤ë°‹ ì•ˆí•¨ (ì¬ì‹œë„ë¨)
        }
    }

    /**
     * ì‹¤íŒ¨í•œ ë©”ì‹œì§€ ì¬ì²˜ë¦¬ ì‹œë„
     */
    private boolean retryFailedMessage(FailedLogMessage failedMessage) {
        try {
            // ì›ë³¸ ë©”ì‹œì§€ë¥¼ ë‹¤ì‹œ Elasticsearch ì— ì €ì¥ ì‹œë„
            apiGatewayLogService.saveLog(failedMessage.getOriginalMessage());

            log.info("ì¬ì²˜ë¦¬ ì„±ê³µ: requestId={}", failedMessage.getRequestId());
            return true;

        } catch (Exception e) {
            log.warn("ì¬ì²˜ë¦¬ ì‹¤íŒ¨: requestId={}, error={}",
                    failedMessage.getRequestId(), e.getMessage());
            return false;
        }
    }

    /**
     * ì˜êµ¬ ì‹¤íŒ¨ ì²˜ë¦¬
     */
    private void handlePermanentFailure(FailedLogMessage failedMessage) {
        log.error("ğŸš¨ ì˜êµ¬ ì‹¤íŒ¨ ë©”ì‹œì§€: requestId={}, errorType={}",
                failedMessage.getRequestId(),
                failedMessage.getErrorType());

        // TODO: ë‹¤ìŒ ì‘ì—… ìˆ˜í–‰
        // 1. DB ì— ì˜êµ¬ ì‹¤íŒ¨ ë ˆì½”ë“œ ì €ì¥
        // 2. ê´€ë¦¬ìì—ê²Œ ì•Œë¦¼ ë°œì†¡ (Slack, Email)
        // 3. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œì— í‘œì‹œ
        // 4. ìˆ˜ë™ ì²˜ë¦¬ ëŒ€ê¸° íì— ì¶”ê°€
    }

    // ==================== DTO ====================

    /**
     * ì‹¤íŒ¨ ë©”ì‹œì§€ DTO
     */
    @lombok.Builder
    @lombok.Getter
    @lombok.AllArgsConstructor
    @lombok.NoArgsConstructor
    private static class FailedLogMessage {
        private ApiGatewayRequestLogDto originalMessage;  // ì›ë³¸ ë©”ì‹œì§€
        private String errorType;                         // ì—ëŸ¬ ìœ í˜•
        private String errorMessage;                      // ì—ëŸ¬ ë©”ì‹œì§€
        private String stackTrace;                        // ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤
        private int retryCount;                           // ì¬ì‹œë„ íšŸìˆ˜
        private LocalDateTime failedAt;                   // ì‹¤íŒ¨ ì‹œê°
        private String requestId;                         // ì¶”ì ìš©
        private String clientId;                          // ì¶”ì ìš©
        private String accessKey;                         // ì¶”ì ìš©
    }
}